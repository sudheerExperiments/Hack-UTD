{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50000\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1482192, 8, 1)\n",
      "Y_train shape: (1482192, 2)\n",
      "X_val shape: (494064, 8, 1)\n",
      "Y_val shape: (494064, 2)      \n",
      "X test shape: (494064, 8, 1)\n",
      "Y test shape: (494064, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load train, validation, and testing data from saved numpy arrays\n",
    "\n",
    "x_train = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_train.npy')\n",
    "y_train = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_train.npy')\n",
    "x_val = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_val.npy')\n",
    "y_val = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_val.npy')\n",
    "x_test = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_test.npy')\n",
    "y_test = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_test.npy')\n",
    "\n",
    "print(\"X train shape: {}\\nY_train shape: {}\\nX_val shape: {}\\nY_val shape: {}\\\n",
    "      \\nX test shape: {}\\nY test shape: {}\".format(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Dense, Dropout, MaxPooling1D, Flatten, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def cnn_model():\n",
    "    inp = Input(shape=x_train.shape[1:])\n",
    "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "    conv1 = BatchNormalization(axis=-1, center=True, scale=True)(conv1)\n",
    "    conv2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization(axis=-1, center=True, scale=True)(conv2)\n",
    "    conv3 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    conv3 = BatchNormalization(axis=-1, center=True, scale=True)(conv3)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv3)\n",
    "    flattern = Flatten()(pool1)\n",
    "    dense1 = Dense(500, activation='relu')(flattern)\n",
    "    classifier = Dense(2, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=classifier)\n",
    "    \n",
    "    opt = Adam(lr=1e-6)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(\n",
    "        filepath='/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Checkpoints/checkpoint.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True), EarlyStopping(monitor='val_mean_squared_error', patience=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 8, 1)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 8, 64)             6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 8, 128)            24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 128)            512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 289,438\n",
      "Trainable params: 288,990\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "print(model.summary())\n",
    "\n",
    "# Train the regressor\n",
    "# model.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=1, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494064/494064 [==============================] - 27s 55us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004024454036856574, 0.004024454036856574]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "load_model('Checkpoints/checkpoint.50-0.01.h5')\n",
    "# Evaluate model with test data\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
