{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50000\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1482192, 8, 1)\n",
      "Y_train shape: (1482192, 2)\n",
      "X_val shape: (494064, 8, 1)\n",
      "Y_val shape: (494064, 2)      \n",
      "X test shape: (494064, 8, 1)\n",
      "Y test shape: (494064, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load train, validation, and testing data from saved numpy arrays\n",
    "\n",
    "x_train = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_train.npy')\n",
    "y_train = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_train.npy')\n",
    "x_val = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_val.npy')\n",
    "y_val = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_val.npy')\n",
    "x_test = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/x_test.npy')\n",
    "y_test = np.load('/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Preprocessed_data/y_test.npy')\n",
    "\n",
    "print(\"X train shape: {}\\nY_train shape: {}\\nX_val shape: {}\\nY_val shape: {}\\\n",
    "      \\nX test shape: {}\\nY test shape: {}\".format(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, Dense, Dropout, MaxPooling1D, Flatten, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def cnn_model():\n",
    "    inp = Input(shape=x_train.shape[1:])\n",
    "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(inp)\n",
    "    conv1 = BatchNormalization(axis=-1, center=True, scale=True)(conv1)\n",
    "    conv2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization(axis=-1, center=True, scale=True)(conv2)\n",
    "    conv3 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    conv3 = BatchNormalization(axis=-1, center=True, scale=True)(conv3)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv3)\n",
    "    flattern = Flatten()(pool1)\n",
    "    dense1 = Dense(500, activation='relu')(flattern)\n",
    "    classifier = Dense(2, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=classifier)\n",
    "    \n",
    "    opt = Adam(lr=1e-6)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(\n",
    "        filepath='/home/phantom/Documents/Electricity_Usage_Forecast_HackUTD/Checkpoints/checkpoint.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True), EarlyStopping(monitor='val_mean_squared_error', patience=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 8, 1)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 8, 64)             6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 64)             256       \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 8, 128)            24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 128)            512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 289,438\n",
      "Trainable params: 288,990\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1482192 samples, validate on 494064 samples\n",
      "Epoch 1/500\n",
      "1482192/1482192 [==============================] - 45s 30us/step - loss: 0.2938 - mean_squared_error: 0.2938 - val_loss: 0.2753 - val_mean_squared_error: 0.2753\n",
      "Epoch 2/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.2680 - mean_squared_error: 0.2680 - val_loss: 0.2505 - val_mean_squared_error: 0.2505\n",
      "Epoch 3/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.2433 - mean_squared_error: 0.2433 - val_loss: 0.2268 - val_mean_squared_error: 0.2268\n",
      "Epoch 4/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.2193 - mean_squared_error: 0.2193 - val_loss: 0.2037 - val_mean_squared_error: 0.2037\n",
      "Epoch 5/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.1960 - mean_squared_error: 0.1960 - val_loss: 0.1814 - val_mean_squared_error: 0.1814\n",
      "Epoch 6/500\n",
      "1482192/1482192 [==============================] - 42s 29us/step - loss: 0.1735 - mean_squared_error: 0.1735 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
      "Epoch 7/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.1524 - mean_squared_error: 0.1524 - val_loss: 0.1407 - val_mean_squared_error: 0.1407\n",
      "Epoch 8/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.1333 - mean_squared_error: 0.1333 - val_loss: 0.1230 - val_mean_squared_error: 0.1230\n",
      "Epoch 9/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.1162 - mean_squared_error: 0.1162 - val_loss: 0.1076 - val_mean_squared_error: 0.1076\n",
      "Epoch 10/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.1013 - mean_squared_error: 0.1013 - val_loss: 0.0942 - val_mean_squared_error: 0.0942\n",
      "Epoch 11/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0885 - mean_squared_error: 0.0885 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 12/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0776 - mean_squared_error: 0.0776 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 13/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0683 - mean_squared_error: 0.0683 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "Epoch 14/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0605 - mean_squared_error: 0.0605 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
      "Epoch 15/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
      "Epoch 16/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "Epoch 17/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
      "Epoch 18/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 19/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
      "Epoch 20/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 21/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0280 - val_mean_squared_error: 0.0280\n",
      "Epoch 22/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 23/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 24/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Epoch 25/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 26/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 27/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 28/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 29/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 30/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 31/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
      "Epoch 32/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "Epoch 33/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 34/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 35/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 36/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "Epoch 37/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 38/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 39/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 40/500\n",
      "1482192/1482192 [==============================] - 44s 30us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 41/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 42/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 43/500\n",
      "1482192/1482192 [==============================] - 44s 30us/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 44/500\n",
      "1482192/1482192 [==============================] - 44s 30us/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 45/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 46/500\n",
      "1482192/1482192 [==============================] - 42s 28us/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 47/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
      "Epoch 48/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 49/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 50/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 51/500\n",
      "1482192/1482192 [==============================] - 44s 30us/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 52/500\n",
      "1482192/1482192 [==============================] - 46s 31us/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
      "Epoch 53/500\n",
      "1482192/1482192 [==============================] - 42s 29us/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 54/500\n",
      "1482192/1482192 [==============================] - 41s 28us/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 55/500\n",
      "1482192/1482192 [==============================] - 44s 30us/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 56/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 57/500\n",
      "1482192/1482192 [==============================] - 43s 29us/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 58/500\n",
      " 850000/1482192 [================>.............] - ETA: 16s - loss: 0.0040 - mean_squared_error: 0.0040"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5ff357762c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Evaluate model with test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "print(model.summary())\n",
    "\n",
    "# Train the regressor\n",
    "# model.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=1, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494064/494064 [==============================] - 27s 55us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004024454036856574, 0.004024454036856574]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "load_model('Checkpoints/checkpoint.50-0.01.h5')\n",
    "# Evaluate model with test data\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
